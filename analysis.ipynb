{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bfa0334",
   "metadata": {},
   "source": [
    "# Project Performance Analysis\n",
    "\n",
    "This notebook explores a synthetic dataset of project performance metrics tailored for roles such as Business Analyst, Program Manager, and Data Analyst. The analysis includes descriptive statistics, visualizations, and predictive modeling to demonstrate how data-driven approaches can inform decision-making in project management.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb10a2c",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "We start by loading the dataset stored in `synthetic_project_data.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Read dataset\n",
    "df = pd.read_csv('synthetic_project_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150357d",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "Next, we examine basic statistics of numerical columns and visualize distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert StartDate and EndDate to datetime for duration calculations\n",
    "df['StartDate'] = pd.to_datetime(df['StartDate'])\n",
    "df['EndDate'] = pd.to_datetime(df['EndDate'])\n",
    "df['DurationActual'] = (df['EndDate'] - df['StartDate']).dt.days\n",
    "\n",
    "# Plot distribution of budgets\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['Budget'], bins=20, kde=True)\n",
    "plt.title('Distribution of Project Budgets')\n",
    "plt.xlabel('Budget')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plot risk levels count\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x='RiskLevel', order=['Low','Medium','High','Critical'])\n",
    "plt.title('Count of Projects by Risk Level')\n",
    "plt.xlabel('Risk Level')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap for numeric features\n",
    "numeric_cols = ['DurationDays','Budget','ActualCost','TeamSize','ScopeComplexity','DurationActual']\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4ef5b",
   "metadata": {},
   "source": [
    "## Predictive Modeling\n",
    "\n",
    "We build two classifiers—logistic regression and random forest—to predict project success.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39827107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df[['DurationDays','Budget','ActualCost','TeamSize','ScopeComplexity']].copy()\n",
    "y = df['Success']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features for logistic regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model_name, y_true, y_pred):\n",
    "    print(model_name)\n",
    "    print('Accuracy:', accuracy_score(y_true, y_pred))\n",
    "    print('Confusion Matrix:\n",
    "', confusion_matrix(y_true, y_pred))\n",
    "    print('Classification Report:\n",
    "', classification_report(y_true, y_pred))\n",
    "    print('-'*50)\n",
    "\n",
    "# Evaluate models\n",
    "evaluate('Logistic Regression', y_test, y_pred_lr)\n",
    "evaluate('Random Forest', y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648bad9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This synthetic dataset and accompanying analysis demonstrate how a combination of descriptive analytics and predictive modeling can be used to assess project performance. You can extend this notebook by exploring feature importance, hyperparameter tuning, or incorporating additional project management variables.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
